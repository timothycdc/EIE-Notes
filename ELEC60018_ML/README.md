# ELEC60019 Machine Learning

- The EEE Department's version of the Machine Learning course.
- I got a bit too carried away in statistical learning theory in some areas.
- These notes are unfinished and have several notational and content errors, including some missing detail from the slide. 
- These errors will be documented after term ends. 
- I do not recommend using these notes for reference during the open-book exam.
- I attempted to cover more of the mathematics behind the concepts, so this might blur the boundary between what is examinable or not â€“ some have been separated under callouts as 'Extra, Not Assessed'.
- Again, these notes are not guaranteed mistake-free nor a perfect match to the syllabus. Use at your own risk, but for your convenience of learning.


### To Do
- [ ] Derivation of Hoeffding's Inequality: Change Proof
- [ ] Section 2.6.4: Clarift in Combinatorial Quantity operator $B(N,k)$
- [ ] Section 2.8: Terminology
- [ ] Section 3.5: Does the loss function approximate true risk better than the VC inequality? Also crop diagram better
- [ ] Section 3.7: Cover Regularised Loss Minimisation, Structural Risk Minimisation
- [ ] Section 4.3: Hinge Loss: Number the section and Note to Reader
- [ ] Section 4.4.0: Improve Neural Network diagram
- [ ] Section 4.4.1 to 4.4.3: More content + explain SGD for Neural Networks
- [ ] Section 5.1.0: Improve Note to Reader
- [ ] Section 5.2: Notes for K-Nearest Neighbours
- [ ] Section 6.1: Notes for Unsupervised Learning
- [ ] Section 6.2: Notes for Linear Autoencoders (fix typo)
- [ ] Section 6.3: Notes for PCA
- [ ] Section 7.1 Notes on Clustering
- [ ] Section 7.2 Notes on K-Means Clustering
- [ ] Section 7.3 Notes on Hierarchical Clustering (fix typo)
